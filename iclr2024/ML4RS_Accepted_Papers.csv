Paper ID;Paper Title;Abstract;Authors;Author Names;Status16;Causal Graph Neural Networks for Wildfire Danger Prediction;"Wildfire forecasting is notoriously hard due to the complex interplay of different factors such as weather conditions, vegetation types and human activities. Deep learning models show promise in dealing with this complexity by learning directly from data. However, to inform critical decision making, we argue that we need models that are right for the right reasons; that is, the implicit rules learned should be grounded by the underlying processes driving wildfires. In that direction, we propose integrating causality with Graph Neural Networks (GNNs) that explicitly model the causal mechanism among complex variables via graph learning. The causal adjacency matrix considers the synergistic effect among variables and removes the spurious links from highly correlated impacts. Our methodology’s effectiveness is demonstrated through superior performance forecasting wildfire patterns in the European boreal and mediterranean biome. The gain is especially prominent in a highly imbalanced dataset, showcasing an enhanced robustness of the model to adapt to regime shifts in functional relationships. Furthermore, SHAP values from our trained model further enhance our understanding of the model’s inner workings.";"Shan Zhao (Technical University of Munich)*; Ioannis Prapas (National Observatory of Athens); Ilektra Karasante (National Observatory of Athens); Zhitong Xiong (Techinical University of Munich); IOANNIS PAPOUTSIS (National Observatory of Athens); Gustau Camps-Valls (Universitat de València); Xiaoxiang Zhu (Technical University of Munich,Germany )";"Zhao, Shan*; Prapas, Ioannis; Karasante, Ilektra; Xiong, Zhitong; PAPOUTSIS, IOANNIS; Camps-Valls, Gustau; Zhu, Xiaoxiang";Accept Oral18;Sparsely Labeled Land Cover Classification with Oversegmentation-based Graph U-Nets;Training neural networks for large-scale land cover classification from satellite imagery requires extensive labels for training and evaluation. While most methods are designed around dense annotations, another promising idea is to rely on sparse labels, such as openly available in-situ data. However, these data pose challenges in terms of model design and training. In this paper, we present a specially designed neural network architecture for sparsely labeled land cover classification from Sentinel-2 images and LUCAS data. Our network is a variant of Graph U-Net which represents images as graphs and uses transformer-inspired graph convolutional layers and pooling layers based on hierarchical image oversegmentations. Additionally, we adapt deep bilateral filtering modules to this architecture. In our experiments, we demonstrate that our network is able to learn from sparse labels more efficiently than traditional approaches, outperforming standard U-Nets.;"Johannes Leonhardt (University of Bonn)*; Ribana Roscher (Forschungszentrum Jülich)";"Leonhardt, Johannes*; Roscher, Ribana";Accept Oral21;Uncertainty Aware Tropical Cyclone Wind Speed Estimation from Satellite Data;Deep neural networks (DNNs) have been successfully applied to earth observation (EO) data and opened new research avenues \citep{tuia2023artificial}. Despite the theoretical and practical advances of these techniques, DNNs are still considered black box tools and by default are designed to give point predictions. However, the majority of EO applications demand reliable uncertainty estimates that can support practitioners in critical decision making tasks. This work provides a theoretical and quantitative comparison of existing uncertainty quantification methods for DNNs applied to the task of wind speed estimation in satellite imagery of tropical cyclones. We provide a detailed evaluation of predictive uncertainty estimates from state-of-the-art uncertainty quantification (UQ) methods for DNNs. We find that predictive uncertainties can be utilized to further improve accuracy and analyze the predictive uncertainties of different methods across storm categories.;"Nils Lehmann (Technical University of Munich)*; Nina Maria Gottschling (DLR); Stefan Depeweg (Technical University of Munich); Eric Nalisnick (Johns Hopkins University)";"Lehmann, Nils*; Gottschling, Nina Maria; Depeweg, Stefan; Nalisnick, Eric";Accept Oral23;CromSS: Cross-modal pre-training with noisy labels for remote sensing image segmentation;We study the potential of noisy labels y to pretrain semantic segmentation models in a multi-modal learning framework for geospatial applications. Specifically, we propose a novel Cross-modal Sample Selection method (CromSS) that utilizes the class distributions (P^(d))(x,c) over pixels x and classes c modelled by multiple sensors/modalities d of a given geospatial scene. Consistency of predictions across sensors d is jointly informed by the entropy of (P^(d))(x,c). Noisy label sampling we determine by the confidence of each sensor d in the noisy class label, (P^(d))(x,c=y(x)). To verify the performance of our approach, we conduct experiments with Sentinel-1 (radar) and Sentinel-2 (optical) satellite imagery from the globally-sampled SSL4EO-S12 dataset. We pair those scenes with 9-class noisy labels sourced from the Google Dynamic World project for pretraining. Transfer learning evaluations (downstream task) on the DFC2020 dataset confirm the effectiveness of the proposed method for remote sensing image segmentation.;"Chenying Liu (German Aerospace Center (dlr))*; Conrad M Albrecht (German Aerospace Center); Yi Wang (Technical University of Munich); Xiaoxiang Zhu (Technical University of Munich,Germany )";"Liu, Chenying*; Albrecht, Conrad M; Wang, Yi; Zhu, Xiaoxiang";Accept Oral26;Leveraging Synthetic Data and Machine Learning for Cloud Optical Thickness Estimation;Cloud formations often obstruct the effectiveness of optical satellite monitoring, imposing limitations on Earth observation (EO) tasks such as land cover mapping, ocean color analysis, and cropland monitoring. While machine learning (ML) methods have improved EO tasks, challenges persist, primarily the dependence on annotated data for ML training, especially in EO contexts like cloud optical thickness (COT) estimation. To address the scarcity of COT data, we propose a synthetic dataset simulating top-of-atmosphere radiances for 12 spectral bands of the MSI sensor on Sentinel-2 platforms, and encompassing various cloud types, COTs, and environmental conditions. Extensive experimentation on training ML models to predict COT from spectral band reflectivities demonstrates the utility of the proposed dataset. Generalization to cloud cover mapping on real data is verified on two satellite image datasets. The data, code and models will be made available.;"Aleksis Pirinen (RISE Research Institutes of Sweden ); Nosheen Abid (Lulea University of Technology)*; György Kovács (Luleå University of Technology); Scheirer Ronald (SMHI); Chiara Ceccobello (AI Sweden); Nuria Agues (RISE); Thomas Ohlson (RISE); Anders Persson (skogsstyrelsen); Marcus Liwicki (Luleå University of Technology)";"Pirinen, Aleksis; Abid, Nosheen*; Kovács, György; Ronald, Scheirer; Ceccobello, Chiara; Agues, Nuria; Ohlson, Thomas; Persson, Anders; Liwicki, Marcus";Accept Oral54;Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data;Large Vision-Language Models (VLMs) have demonstrated impressive performance on complex tasks involving visual input with natural language instructions. However, it remains unclear to what extent capabilities on natural images transfer to Earth observation (EO) data, which are predominantly satellite and aerial images less common in VLM training data. In this work, we propose a comprehensive benchmark to gauge the progress of VLMs toward being useful tools for EO data by assessing their abilities on scene understanding, localization and counting, and change detection tasks. Motivated by real-world applications, our benchmark includes scenarios like urban monitoring, disaster relief, land use, and conservation. We discover that, although state-of-the-art VLMs like GPT-4V possess extensive world knowledge that leads to strong performance on open-ended tasks like location understanding and image captioning, their poor spatial reasoning limits usefulness on object localization and counting tasks. Our benchmark will be made publicly available on Hugging Face.;"Chenhui Zhang (Institute for Data, Systems, and Society, Massachusetts Institute of technology)*; Sherrie Wang (MIT)";"Zhang, Chenhui*; Wang, Sherrie";Accept Oral65;EVALUATING TOOL-AUGMENTED AGENTS IN REMOTE SENSING PLATFORMS;Tool-augmented Large Language Models (LLMs) have shown impressive capabilities in remote sensing (RS) applications. However, existing benchmarks assume question-answering input templates over predefined image-text data pairs. These standalone instructions neglect the intricacies of realistic user grounded tasks. Consider a geospatial analyst: they zoom in a map area, they draw a region over which to collect satellite imagery, and they succinctly ask ``Detect all objects here''. Where is `here`, if it is not explicitly hardcoded in the image-text template, but instead is implied by the system state, e.g., live map positioning? To bridge this gap, we present Geo-ToolQA, a benchmark designed to capture long sequences of verbal, visual, and click-based actions on a real UI platform. Through in-depth evaluation of state-of-the-art LLMs over a diverse set of 500 tasks, we offer insights towards stronger agents for RS applications.;"Simranjit Singh (Microsoft)*; Michael Fore (Microsoft); Dimitrios Stamoulis (Microsoft)";"Singh, Simranjit*; Fore, Michael; Stamoulis, Dimitrios";Accept Oral2;Learned Embedding Fields for Multi-Source, Multi-Temporal Earth Observation Imagery;"Earth observation data is plentiful, but the ease of analysis varies across data sources and products due to differences in packaging, processing, and the nuances of inputs and tasks.
Analysis-ready datasets seek to enable broader and more convenient use of Earth observations by offering effective processing of the upstream data to facilitate analysis for downstream use cases. We propose embedding fields, our novel geo-spatial-temporal representation, as a learned form of analysis-ready dataset. Our representation is learned by optimizing a deep network on multi-source (multiple sensor) and multi-temporal (multiple time step) data without annotations. By learning our embedding fields we are able to incorporate more inputs for accuracy while compressing the size of the output for efficiency. Our representation is applied by computing it only once for the desired spatial and temporal scopes, to amortize the cost of analyses, then indexing by latitude, longitude, and year. We compare our learned embedding fields with MOSAIKS, a designed form of analysis-ready dataset, that also seeks to serve its representation as data. Because annotation scarcity is common in practice, we evaluate our embedding fields and MOSAIKS on multiple tasks in few-shot regimes. Our results indicate that embedding fields improve accuracy across all tasks considered while reducing inference computation for varied geographies (the United States, Indonesia, Malaysia) and types of annotations (land use, tree species distribution, and ecological regions).";"Christopher F Brown (DeepMind); Michal R Kazmierski (Google DeepMind); William J Rucklidge (Google); Valerie J. Pasquarella (Google LLC); Evan Shelhamer (DeepMind)*";"Brown, Christopher F; Kazmierski, Michal R; Rucklidge, William J; Pasquarella, Valerie J.; Shelhamer, Evan*";Accept Poster4;GIMI: A Geographical Generalizable Image-to-Image Search Engine with Location-explicit Contrastive Embedding;To query and localize objects of interest among massive and multi-modality big geospatial data (BGD) is fundamental in spatial data science and Earth system science (ESS). However, the effective and efficient searching among an extensive collection of geospatial data (e.g., global satellite imagery) for interesting patterns can be challenging, often requiring domain-specific prior knowledge (i.e., training labels) and intensive computational resources. Towards addressing this challenge, we introduce GIMI, a geographical generalizable image-to-image neural search engine that extends \textit{the cluster hypothesis} from information retrieval theory - closely associated documents tend to be relevant to the same requests - to geospatial data. We explicitly integrate geo-location information into the contrastive learning of image embeddings via a general distance-penalized triplet loss. On this basis, GIMI is designed to support a wide range of search queries, including embedding-based similar search and spatial-constrained nearest neighborhood search. As a case study, we select the task of post-disaster damage building search to demonstrate the general idea behind GIMI and evaluate its model performance in a critical real-world searching scenario. Experiments show that GIMI achieves promising searching performance, w.r.t accuracy and efficiency, in selected areas affected by the 2023 Kahramanmara_ Earthquake in Turkey;"Hao Li (Technical Universtiy of Munich)*; Jiapan Wang (Professorship of Big Geospatial Data Management, Technical University of Munich); Balthasar Teuscher (Techinical Unviersity of Munich); Peng Luo (Technical University of Munich); Danfeng Hong (Chinese Academy of Sciences); Gengchen Mai (University of Georgia); Martin Werner (TU München)";"Li, Hao*; Wang, Jiapan; Teuscher, Balthasar; Luo, Peng; Hong, Danfeng; Mai, Gengchen; Werner, Martin";Accept Poster6;Uncertainty quantification for probabilistic machine learning in earth observation using conformal prediction.;"Machine learning is applied to Earth Observation (EO) data to derive data sets that
are used to characterise, comprehend and conserve natural resources, contributing
to progress towards international accords. However, the derived datasets contain
inherent uncertainty and need to be quantified reliably to avoid negative downstream
consequences. In response to the increased need to report uncertainty,
we bring attention to the promise of conformal prediction within the domain of
EO. Conformal prediction is an Uncertainty Quantification (UQ) method that offers
statistically valid and informative prediction regions while concurrently being
computationally efficient, model-agnostic, distribution-free and can be applied in
a post-hoc manner without requiring access to the underlying model and training
dataset. We assessed the current state of uncertainty quantification in the EO domain
and found that only 20% of the reviewed datasets incorporated a degree of
uncertainty information, with unreliable methods prevalent. Next, we introduce
Google Earth Engine native modules that can integrate into existing predictive
modelling workflows and demonstrate the versatility, efficiency, and scalability
of these tools by applying them to datasets spanning continental to global scales,
regression, and classification tasks, featuring both traditional and deep learningbased
workflows. We anticipate that the increased availability of easy-to-use implementations
of conformal predictors, such as those provided here, will drive
wider adoption of rigorous uncertainty quantification in EO, thereby enhancing
the reliability of uses such as operational monitoring and decision-making.";Geethen Singh (Stellenbosch University)*;Singh, Geethen*;Accept Poster9;Super-resolution of Sentinel-1 Imagery Using an Enhanced Attention Network and Real Ground Truth Data;Active imaging systems, particularly Synthetic Aperture Radar (SAR), offer notable advantages such as the ability to operate in diverse weather conditions and provide day and night observations of Earth's surface. These attributes are especially valuable when monitoring regions consistently obscured by clouds, as seen in Northern Europe. One of the most recognized SAR constellations is Sentinel-1 (S1), known for providing imagery freely to the community. Despite this accessibility, problems arise due to the inherent limitations of the spatial resolution of S1 and the presence of speckle noise, which makes the data difficult to interpret. Although there are several commercial SAR satellites offering on-demand high-resolution data, their high costs hinder their use among remote sensing experts. Motivated by the outlined advantages and limitations, this paper introduces a novel deep learning-based methodology aimed at simultaneously reducing speckle noise and enhancing the spatial resolution of S1 data. Contrary to previous works that rely on a high-resolution satellite as ground truth (typically  TerraSAR-X), we propose to use the same satellite in another operational mode as ground truth. Accordingly, the proposed method focuses on enhancing the spatial resolution of S1 Interferometric Wide Swath mode products from 10 to 5 m GSD by leveraging S1 Stripmap mode as the ground truth for training the model. As a result, super-resolved images duplicated the input spatial resolution, closing the gap between S1 and commercial SAR satellites.;"Christian Ayala (Tracasa Instrumental)*; Juan Francisco Amieva (Tracasa Instrumental); Mikel Galar (Universidad Pública de Navarra)";"Ayala, Christian*; Amieva, Juan Francisco; Galar, Mikel";Accept Poster10;Multi-stage semantic segmentation to map small and sparsely distributed habitats;Land cover (LC) maps are used extensively for nature conservation and landscape planning, but low spatial resolution and coarse LC schemes typically limit their applicability to large, broadly-defined habitats. In order to target smaller and more specific habitats, LC maps must be developed at high resolution and fine class detail, using methods that can handle strong class imbalance. Multi-stage semantic segmentation to map small and sparsely distributed habitatsIn this work, we present a new aerial photography data set with 12.5 cm ground resolution, annotated using a detailed, hierarchical land cover schema. We show that splitting up the semantic segmentation process into multiple stages critically improves the predictive performance, in particular by including the rare LC classes. We then apply this method to create a new LC map of the Peak District National Park (1439 km2), England, at 12.5 cm resolution.;"Thijs Lambik van der Plas (Alan Turing Institute)*; Simon Geikie ( Peak District National Park Authority); David Alexander (Peak District National Park Authority); Daniel Simms (Cranfield University)";"van der Plas, Thijs Lambik*; Geikie, Simon; Alexander, David; Simms, Daniel";Accept Poster11;Noise2Noise Denoising of CRISM Hyperspectral Data;Hyperspectral data acquired by the Compact Reconnaissance Imaging Spectrometer for Mars (CRISM) have allowed for unparalleled mapping of the surface mineralogy of Mars. Due to sensor degradation over time, a significant portion of the recently acquired data is considered unusable. Here a new data-driven model architecture, Noise2Noise4Mars (N2N4M), is introduced to remove noise from CRISM images. Our model is self-supervised and does not require zero-noise target data, making it well suited for use in Planetary Science applications where high quality labelled data is scarce. We demonstrate its strong performance on synthetic-noise data and CRISM images, and its impact on downstream classification performance, outperforming benchmark methods on most metrics. This allows for detailed analysis for critical sites of interest on the Martian surface, including proposed lander sites.;"Robert Platt (Imperial College London)*; Cedric John (Digital Environment Research Institute, Queen Mary University of London); Rossella Arcucci (Imperial College London)";"Platt, Robert*; John, Cedric; Arcucci, Rossella";Accept Poster13;A Concise Tiling Strategy for Preserving Spatial Context in Earth Observation Imagery;We propose a new tiling strategy, Flip-n-Slide, which has been developed for specific use with large Earth observation satellite images when the location of objects-of-interest (OoI) is unknown and spatial context can be necessary for class disambiguation. Flip-n-Slide is a concise and minimalistic approach that allows OoI to be represented at multiple tile positions and orientations. This strategy introduces multiple views of spatio-contextual information, without introducing redundancies into the training set. By maintaining distinct transformation permutations for each tile overlap, we enhance the generalizability of the training set without misrepresenting the true data distribution. Our experiments validate the effectiveness of Flip-n-Slide in the task of semantic segmentation, a necessary data product in geophysical studies. We find that Flip-n-Slide outperforms the previous state-of-the-art augmentation routines for tiled data in all evaluation metrics. For underrepresented classes, Flip-n-Slide increases precision by as much as 15.8%.;"Ellianna Abrahams (UC Berkeley)*; Tasha Snow (Colorado School of Mines); Fernando Pérez (UC Berkeley); Matthew Siegfried (Colorado School of Mines)";"Abrahams, Ellianna*; Snow, Tasha; Pérez, Fernando; Siegfried, Matthew";Accept Poster14;Impact of Missing Views in Multi-view Model Predictions for Vegetation Applications;"Earth observation (EO) applications involving complex and heterogeneous data sources are commonly approached with machine learning models. However, there is a common assumption that data sources will be persistently available. Different situations could affect the availability of EO sources, like noise, clouds, or satellite mission failures. In this work, we assess the impact of missing temporal and
static EO sources in trained models across two datasets involving classification and regression tasks. We compare the predictive quality of different methods and find that some are naturally more robust to missing data. The Ensemble strategy, in particular, achieves a prediction robustness up to 99%. We evidence that missing
scenarios are more challenging in regression than classification tasks. Finally, we find that the optical view is the most critical view when it is missing individually.";"Francisco Mena (University of Kaiserslautern-Landau & DFKI GmbH)*; Diego Arenas (German Research Center for Artificial Intelligence); Marlon Nuske (DFKI GmbH); Andreas Dengel (DFKI GmbH)";"Mena, Francisco*; Arenas, Diego; Nuske, Marlon; Dengel, Andreas";Accept Poster17;Integrating physics deductive biases into learning for hyperspectral classification;Airborne hyperspectral imaging has great potential for land cover mapping with very detailed nomenclatures thanks to its spectral dimension, which is highly informative about the chemical composition of matter. In the past years, the scarcity of training data in regards to the significant spectral intra-class variability has motivated the development of inductive biases for the generalization of deep learning classification models. In contrast, we investigate in this paper an orthogonal line of research which consists in integrating deductive biases derived from a priori physical knowledge into weakly supervised learning in order to improve the robustness of classification models to changes in local irradiance conditions. Our experiments on simulated and real data demonstrate the benefits of our method in terms of classification accuracy.;Romain Thoreau (CNES)*;Thoreau, Romain*;Accept Poster24;AI-powered School Mapping and Connectivity Status Prediction using Earth Observation;Digital connectivity is essential for advancing UN SDG4: quality education. Accurate and complete information on the locations of schools and their connectivity status is crucial for identifying gaps in infrastructure. In this work, we introduce a novel AI-enabled school mapping and internet connectivity status prediction workflow, in support of digital capacity building. First, we investigate the performance of state-of-the-art computer vision models for school mapping. Next, we introduce a connectivity prediction model using machine learning and publicly available remote sensing data. We evaluate our approach in five pilot countries: Bosnia and Herzegovina, Belize, Botswana, Guinea, and Rwanda. Finally, as a proof-of-concept, we run our pipeline end-to-end in 10 districts in Botswana.;"Kelsey Doerksen (UNICEF); Isabelle Tingzon (UNICEF)*; Dohyung Kim (UNICEF)";"Doerksen, Kelsey; Tingzon, Isabelle*; Kim, Dohyung";Accept Poster28;Towards general deep-learning-based tree instance segmentation models;The segmentation of individual trees from forest point clouds is a crucial task for downstream analyses such as carbon sequestration estimation. Recently, deep-learning-based methods have been proposed which show the potential of learning to segment trees. Since these methods are trained in a supervised way, the question arises how general models can be obtained that are applicable across a wide range of settings. So far, training has been mainly conducted with data from one specific laser scanning type and for specific types of forests. In this work, we train one segmentation model under various conditions, using seven diverse datasets found in literature, to gain insights into the generalization capabilities under domain-shift. Our results suggest that a generalization from coniferous dominated sparse point clouds to deciduous dominated high-resolution point clouds is possible. However, to obtain strong general segmentation models diverse training data from different laser scanners and forest types is necessary. To contribute to a more diverse data basis for model development, labeled trees from two previous works were adapted to the complete forest point cloud and are made publicly available. ;"Jonathan Henrich (Universität Göttingen / Chair of Statistics and Econometrics)*; Jan van Delden (Universität Göttingen / Neural Data Science Group)";"Henrich, Jonathan*; van Delden, Jan";Accept Poster29;Composite Augmentations for Semantic Segmentation in Aerial Images with Few Samples;Remote sensing and computer vision have the potential to enable comprehensive population monitoring to inform wildlife and biodiversity conservation. However, annotated datasets of wildlife in-situ are often difficult, expensive, and time-consuming to procure. This paper proposes a computational and data efficient method to synthesize composite images to supplement real-world data in data-sparse environments with few positive samples. We evaluated our method on three aerial remote sensing datasets and demonstrated a 3% increase in target-class IoU scores. We aim to use this method with a novel aerial dataset of the Boreal forest for ungulate monitoring, which is presently under development.;"Pranav Chandramouli (University of Saskatchewan)*; Ian  Stavness (University of Saskatchewan); Phillip McLoughlin (University of Saskatchewan); Branden Neufeld (University of Saskatchewan)";"Chandramouli, Pranav*; Stavness, Ian ; McLoughlin, Phillip; Neufeld, Branden";Accept Poster31;On the Relevance of SAR and Optical Modalities in Deep Learning based Data Fusion;In preparation of SAR-optical fusion data sets often cloudy samples are removed from the optical component, if these do not contain any information for the prediction task. Although optical data contains more and easier to extract information and SAR data is more noisy, the latter is less affected by changes in the location or illumination and is not blinded by cloud coverage. By removing clouds from the data set, utilizing the SAR features and the often realistic situation of cloud coverage is withheld from the network during training. In this work we show on publicly available pre-trained networks and two remote sensing data sets, that the effort for the filtering and correction of clouds might be not needed. In contrast, the results of self trained ResNet18 networks indicate, that having cloudy examples in the data set might lead to a more informative feature extraction from the SAR modality. This leads to networks which utilize the SAR modality more properly, leading to an increased relevance of the SAR modality and improved accuracy, not only on cloudy test samples but potentially also on clear test data.\footnote{We are planning to publish our code and models};"Jakob Gawlikowski (German Aerospace Center (DLR))*; Nina Maria Gottschling (DLR)";"Gawlikowski, Jakob*; Gottschling, Nina Maria";Accept Poster32;Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI;Remote sensing (RS) applications in the space domain demand machine learning (ML) models that are reliable, robust, and quality-assured, making red teaming a vital approach for identifying and exposing potential flaws and biases. Since both fields advance independently, there is a notable gap in integrating red teaming strategies into RS. This paper introduces a methodology for examining ML models operating on hyperspectral images within the HYPERVIEW challenge, focusing on soil parameters’ estimation. We use post-hoc explanation methods from the Explainable AI (XAI) domain to critically assess the best performing model that won the HYPERVIEW challenge and served as an inspiration for the model deployed on board the INTUITION-1 hyperspectral mission. Our approach effectively red teams the model by pinpointing and validating key shortcomings, constructing a model that achieves comparable performance using just 1% of the input features and a mere up to 5% performance loss. Additionally, we propose a novel way of visualizing explanations that integrate domain specific information about hyperspectral bands (wavelengths) and data transformations to better suit interpreting models for hyperspectral image analysis.;"Vladimir Zaigrajew (Warsaw University of Technology)*; Hubert Baniecki (University of Warsaw); Lukasz Tulczyjew (Silesian University of Technology, KP Labs); Agata Maria Wijata (Silesian University of Technology); Jakub Nalepa (Silesian University of Technology); Nicolas Longepe (ESA); Przemyslaw Biecek (Warsaw University of Technology)";"Zaigrajew, Vladimir*; Baniecki, Hubert; Tulczyjew, Lukasz; Wijata, Agata Maria; Nalepa, Jakub; Longepe, Nicolas; Biecek, Przemyslaw";Accept Poster33;LEVERAGING 3D MODEL IMAGERY TO ESTIMATE A NEW WINDOW VIEW INDEX;We yearn for a connection with nature and a sense of refuge from where we live and the views from our homes. Despite these inclinations, existing window view indices are often time-consuming to collect and over-simplified in their construction. The limited research can be attributed to the lack of data and computational methods for analyzing vistas from properties. To address this gap, this study will leverage the newly available photo-realistic 3D modelled imagery from Google Maps, along with machine learning techniques to improve housing price/rent prediction and to establish a novel window view index for automatically assessing the appeal of views.;"Stephen Law (University College London)*; Steven Stalder (Swiss Data Science Center); Esra Suel (University College London); Atsushi Takizawa (Osaka Metropolitan University)";"Law, Stephen*; Stalder, Steven; Suel, Esra; Takizawa, Atsushi";Accept Poster34;High-resolution Multi-spectral Image Guided DEM Super-resolution using Sinkhorn Regularized Adversarial Network;Digital Elevation Model (DEM) is an essential aspect in the remote sensing domain to analyze and explore different applications related to surface elevation information. In this study, we intend to address the generation of high-resolution (HR) DEMs guided by HR multi-spectral (MX) satellite imagery as prior. To promptly regulate this process, we utilize the discriminator activations as spatial attention for the MX prior, and also introduce a Densely connected Multi-Residual Block (DMRB) module to assist in efficient gradient flow. Further, we present the notion of using Sinkhorn distance with traditional GAN to improve the stability of adversarial learning. In this regard, we provide both theoretical and empirical substantiation of better performance in terms of vanishing gradient issues and numerical convergence. We demonstrate both qualitative and quantitative outcomes with available state-of-the-art methods. Based on our experiments on DEM datasets of Shuttle Radar Topographic Mission (SRTM) and Cartosat-1, we show that the proposed model performs preferably against other benchmark methods. We also generate and visualize several high-resolution DEMs covering terrains with diverse signatures to show the performance of our model.;"Subhajit Paul (Space Applications Centre)*; Ashutosh Gupta (Indian Space Research Organization)";"Paul, Subhajit*; Gupta, Ashutosh";Accept Poster35;Efficient Remote Sensing with Harmonized Transfer Learning and Modality Alignment;"With the rise of Visual and Language Pretraining (VLP), an increasing number of downstream tasks are adopting the paradigm of pretraining followed by fine-tuning. Although this paradigm has demonstrated potential in various multimodal downstream tasks, its implementation in the remote sensing domain encounters some obstacles. Specifically, the tendency for same-modality embeddings to cluster together impedes efficient transfer learning. To tackle this issue, we review the aim of multimodal transfer learning for downstream tasks from a unified perspective, and rethink the optimization process based on three distinct objectives. We propose ""Harmonized Transfer Learning and Modality Alignment (HarMA)"", a method that simultaneously satisfies task constraints, modality alignment, and single-modality uniform alignment, while minimizing training overhead through parameter-efficient fine-tuning. HarMA can be integrated into almost all existing multimodal pretraining models. Remarkably, using the pretrained weights of GeoRSCLIP, HarMA achieves state-of-the-art performance in two popular multimodal retrieval tasks in the remote sensing field, without the need for external data for training. Even with minimal parameter adjustments, HarMA outperforms the fully fine-tuned GeoRSCLIP in image-text retrieval tasks on RSICD and RSITMD. Code will be released on https://anonymous.4open.science/r/HarMA-62BF/.";Tengjun Huang (Shandong University)*;Huang, Tengjun*;Accept Poster37;Exploring selective simple image matching methods for Unsupervised Domain adaptation of urban canopy cover and height prediction;We explore methods for adapting a trained multi-task UNet which predicts canopy cover and height to a new geographic setting using remotely sensed data. Extending previous research, we followed a selective alignment process to identify similar images in the two geographical domains and then tested an array of data-based unsupervised domain adaptation approaches in a zero-shot setting as well as with a small amount of fine-tuning. We find that the selective aligned data-based image matching methods produce promising results in a zero-shot setting, and even more so with a small amount of fine-tuning. These methods outperform both an untransformed baseline and a popular data-based image-to-image translation model. The best performing methods were pixel distribution adaptation and fourier domain adaptation on the canopy cover and height tasks respectively.;"John Francis (The Alan Turing Institute)*; Stephen Law (University College London)";"Francis, John*; Law, Stephen";Accept Poster40;Impacts of Color and Texture Distortions on Earth Observation Data in Deep Learning;Land cover classification and change detection are two important applications of remote sensing and Earth observation (EO) that have benefited greatly from the advances of deep learning. Convolutional and transformer-based U-net models are the state-of-the-art architectures for these tasks, and their performances have been boosted by an increased availability of large-scale annotated EO datasets. However, the influence of different visual characteristics of the input EO data on a model’s predictions is not well understood. In this work we systematically examine model sensitivities with respect to several color- and texture-based distortions on the input EO data during inference, given models that have been trained without such distortions. We conduct experiments with multiple state-of-the-art segmentation networks for land cover classification and show that they are in general more sensitive to texture than to color distortions. Beyond revealing intriguing characteristics of widely used land cover classification models, our results can also be used to guide the development of more robust models within the EO domain.;"Martin Willbo (RISE)*; Aleksis Pirinen (RISE Research Institutes of Sweden ); John Martinsson (Research institutes of Sweden); Edvin Listo Zec (RISE Research institutes of Sweden); Olof Mogren (RISE Research Institutes of Sweden); Mikael Nilsson (Lund University)";"Willbo, Martin*; Pirinen, Aleksis; Martinsson, John; Listo Zec, Edvin; Mogren, Olof; Nilsson, Mikael";Accept Poster41;Towards Climate Variable Prediction with Conditioned Spatio-Temporal Normalizing Flows;This study investigates how conditional normalizing flows can be applied to remote sensing data products in climate science. The method is chosen due to its desired properties such as exact likelihood computation, predictive uncertainty estimation and efficient inference and sampling which facilitates faster exploration of climate scenarios and handling missing data. Experiments show the method is able to capture spatio-temporal correlations and extrapolates well beyond the training time horizon. These insights contribute to the broader field of spatio-temporal modeling, offering potential applications across diverse scientific disciplines.;"Christina Elisabeth Winkler (Mila)*; David Rolnick (Mila AI Research)";"Winkler, Christina Elisabeth*; Rolnick, David";Accept Poster43;Limitations of non-traditional data: evaluating satellite data and OpenStreetMap for predicting spatio-temporal variation in material wealth;Granular and repeated measurements of material wealth are essential for understanding and improving economic livelihoods, but detailed survey data is scarce, especially in Africa --- the continent most affected by poverty. Recent machine learning approaches successfully leverage non-traditional data sources such as satellite data to predict material wealth across locations but not its variation over time. This work systematically investigates the potential of publicly available satellite and OpenStreetMap data to predict levels and fluctuations in annual consumption expenditure and asset wealth at the village level. Models trained on panel data from five African countries between 2007 and 2021 explain up to 50% of spatial variation but struggle to explain temporal variation (R^2<0.04). This has important implications for retrospective policy evaluation, highlighting that in many contexts, non-traditional data sources cannot replace traditional survey data. Considering more nuanced input data constitutes a promising avenue for future research.;"Nathanael Schmidt-Ott (University of Göttingen)*; Krisztina Kis-Katos (University of Göttingen)";"Schmidt-Ott, Nathanael*; Kis-Katos, Krisztina";Accept Poster45;Global Above-Ground Biomass Density Estimation from Sentinel-2 Imagery;The assessment of above ground biomass density (ABGD) is essential for understanding the global carbon cycle and its impact on environmental dynamics. Despite advances in remote sensing technologies, the accurate estimation of biomass at fine spatial resolutions still presents challenges due to data gaps. Here, we propose a deep learning approach using Convolutional Neural Networks (CNNs) for global AGBD estimation at a 10-meter ground sampling distance. This approach is informed by near-real-time Sentinel-2 multispectral imagery and sparse GEDI LiDAR data. Our method adapts a CNN architecture initially created for canopy height mapping, is systematically assessed through various experiments considering geolocation, topographical, and climate data inputs. The best performing model achieves a mean absolute error of 35.9 Mg/ha and a root mean square error  of 81.1 Mg/ha, showcasing competitive performance across continents against a global test set of over 300,000 samples. Notably, the inclusion of DEM elevations and geo-coordinates considerably improves AGBD predictions compared to the base model. The proposed method operates effectively without the need for extensive ground survey data, offering the potential for frequent updates to biomass density maps thanks to the revisit capability of Sentinel-2 satellites.;"Max Bereczky (OroraTech GmbH); Ka  Hei (OroraTech GmbH); Dima Rashkovetsky (OroraTech GmbH); Julia Gottfriedsen (OroraTech GmbH)*";"Bereczky, Max; Hei, Ka ; Rashkovetsky, Dima; Gottfriedsen, Julia*";Accept Poster46;A Change Detection Reality Check;Remote sensing image literature from the past several years has exploded with proposed deep learning architectures that claim to be the latest state-of-the-art on standard change detection benchmark datasets. However, has the field truly made significant progress? In this paper we perform experiments which conclude a simple U-Net segmentation baseline without training tricks or complicated architectural changes is still a top performer for the task of change detection.;"Isaac A Corley (University of Texas at San Antonio)*; Caleb Robinson (Microsoft AI for Good Research Lab); Anthony Ortiz (Microsoft)";"Corley, Isaac A*; Robinson, Caleb; Ortiz, Anthony";Accept Poster48;Global Mapping of Exposure and Physical Vulnerability Dynamics in Least Developed Countries using Remote Sensing and Machine Learning;As the world marked the midterm implementation of the Sendai Framework for Disaster Risk Reduction (SFDRR) 2015-2030, many countries, particularly those least developed, are still struggling to monitor their climate and disaster risk because of the expensive large-scale survey of the distribution of exposure and physical vulnerability and, hence, are not on track in reducing risks amidst the intensifying effects of climate change through the years. We present an ongoing effort in mapping this vital information using time-series remote sensing from publicly available Sentinel-1/2 medium-resolution imagery and deep learning. We introduce the development of OpenSendaiBench that covers 47 least developed countries, tested using a ResNet-50 deep learning baseline, and demonstrated the high-risk city of Dhaka, Bangladesh. As a pioneering effort in auditing global disaster risk over time, this paper aims to bridge the gap between machine learning and disaster risk science communities and to bring into awareness this timely and relevant interdisciplinary problem to advance the area of large-scale risk quantification to ultimately inform our collective SFDRR and post-2030 long-term efforts in reducing climate and disaster risk.;Joshua T Dimasaka (University of Cambridge)*;Dimasaka, Joshua T*;Accept Poster49;Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery;Rare object detection is a fundamental task in applied geospatial machine learning, however is often challenging due to large amounts of high-resolution satellite or aerial imagery and few or no labeled positive samples to start with. This paper addresses the problem of bootstrapping such a rare object detection task assuming there is no labeled data and no spatial prior over the area of interest. We propose novel offline and online cluster-based approaches for sampling patches that are significantly more efficient, in terms of exposing positive samples to a human annotator, than random sampling. We apply our methods for identifying bomas, or small enclosures for herd animals, in the Serengeti Mara region of Kenya and Tanzania. We demonstrate a significant enhancement in detection efficiency, achieving a positive sampling rate increase from 2% (random) to 30%. This advancement enables effective machine learning mapping even with minimal labeling budgets, exemplified by an F1 score on the boma detection task of 0.51 with a budget of 300 total patches.;"Akram Zaytar (Microsoft)*; Caleb Robinson (Microsoft AI for Good Research Lab); Gilles Quentin Hacheme (Microsoft AI for Good Research Lab); Girmaw Abebe Tadesse (Microsoft AI for Good Research Lab); Rahul  Dodhia (Microsoft); Juan M Lavista Ferres (Microsoft)";"Zaytar, Akram*; Robinson, Caleb; Quentin Hacheme, Gilles; Tadesse, Girmaw Abebe; Dodhia, Rahul ; Lavista Ferres, Juan M";Accept Poster50;Tales from the factory floor: Crop Type Classification at Continental Scales in Industry;"Our paper presents our industry-based perspectives and experiences in crop-type classification with deep learning and satellite image time series (SITS) data, in a commercial context at scale. We highlight our approach of using minimally pre-processed data alongside a modified attention-based (LTAE) architecture. We provide a use-case-driven perspective on deciding crop types to classify alongside results showing that challenging crops can be distinguished effectively. We also discuss ""even less processed SITS"" as our model inputs, and present a low-tech approach to model spatial transferability via large and diverse supervised model training. Further, we emphasize numerous avenues for future high-impact research and welcome interaction and collaboration between industry and academia.";"Samuel J Barrett (Regrow Ag)*; Ana Toro (Regrow Ag)";"Barrett, Samuel J*; Toro, Ana";Accept Poster51;ESO: Evolutionary Spectrogram Optimisation for Passive Acoustic Monitoring;Passive Acoustic Monitoring provides an important tool for wildlife monitoring. Deep Learning and the use of convolutional neural networks have become the common approach to create bioacoustic classifiers. However, in order to perform these tasks in real-time, standard approaches suffer from high model complexity and computationally expensive pre-processing steps (such as downsampling). In this paper we introduce a genetic algorithm named ESO, designed to optimise the input spectrogram size by focusing on specific regions. This approach allows for significant reduction in model complexity (91%) and inference time (70%) with minimal impact on the F1-Score (4%). We furthermore develop a simple-to-use Graphical User Interface and Python package to run the algorithm.;"Ufuk Çakır (Heidelberg University)*; Lorène LJ Jeantet (African Institute for Mathematical Sciences); Aaron Joel A J Lontsi Sob (AIMS); Emmanuel Dufourq (African Institute for Mathematical Sciences)";"Çakır, Ufuk*; Jeantet, Lorène LJ; Lontsi Sob, Aaron Joel A J; Dufourq, Emmanuel";Accept Poster53;Spatiotemporal Rockfall Detection Using Point-Based Neural Networks;Rockfall poses a significant threat to human life and infrastructure in mountainous regions, necessitating effective detection and mitigation strategies. Sensor technologies, such as Terrestrial Laser Scanners, are being widely utilized to periodically scan mountain terrains and cliffs acquiring 3D point clouds. Current research on intelligent rockfall detection utilizes pre-computed features and machine-learning models, clearly lacking hidden geometric properties inherent in 3D point clouds. Also, recent point-based deep learning approaches that focus on geometric feature extraction and end-to-end learning, mainly study datasets with balanced labeled observations, not addressing the rockfall class imbalance in real-world cases. Our approach builds upon advancements in point-based neural networks and integrates spatiotemporal information to enhance accuracy and efficiency in detecting rockfall candidates in cases where rockfall observations are limited. Addressing the class imbalance issue inherent in rockfall detection, we present results in real-world 3D scans from a cliff in Spain showcasing the effectiveness of our method in accurately identifying rockfall events.;"Thanasis - Zoumpekas (University of Barcelona)*; Anna Puig; Maria Salamó (University of Barcelona)";"Zoumpekas, Thanasis -*; Puig, Anna; Salamó, Maria";Accept Poster55;Leveraging Deep Learning for the Reconstruction of Plant Hyperspectral Data from RGB Images;Hyperspectral imaging is an important tool used in plant health assessment. It allows for early detection of plant stress which allows for timely intervention and thus improved conservation efforts. However, the high cost and complexity of hyperspectral cameras has limited their usage. To mitigate this issue, the problem of reconstructing plant hyperspectral data from RGB images is investigated. The proposed model reconstructs the visual and near-infrared range (400 - 1000 nm) while being trained solely on images of vegetation, in contrast with existing “generic” models. It is hypothesized that training a less complex model on a specific material will achieve good accuracy even with a relatively small training dataset. The HSCNN-D model is adopted with a simplified architecture. Despite being much smaller than the original model, it achieves comparable performance to state-of-the-art models on images of vegetation.;"Serge Sarkis (American University of Beirut); Ibrahim Issa (American University of Beirut)*; Dany Abou Jaoude (American University of Beirut); Salma Talhouk (American University of Beirut)";"Sarkis, Serge; Issa, Ibrahim*; Abou Jaoude, Dany; Talhouk, Salma";Accept Poster56;Learning Source Domain Representations for Electro-Optical to SAR Transfer;Embedding distribution alignment is an approach to transfer knowledge from label-abundant electro-optical (EO) images to the label-scarce synthetic aperture radar (SAR) modality. However, this approach assumes that it is possible to learn a useful and discriminative EO representation via a neural network. In this work, we study the properties of such a representation. We analyze a recent result showing that supervised contrastive learning can improve transfer performance and find that its reduction of the effective dimension of the embedding is crucial to successful transfer. We then show that directly optimizing for this property can yield even better down-stream accuracy. Finally, we show that the powerful representation of an EO foundation model is insufficient for alignment due to its generality, but that additional representation learning can recover alignment performance.;"Boya Zeng (University of Pennsylvania)*; Marcel Hussing (University of Pennsylvania); Eric Eaton (University of Pennsylvania)";"Zeng, Boya*; Hussing, Marcel; Eaton, Eric";Accept Poster59;REGION-LEVEL LABELS IN ICE CHARTS CAN PRODUCE PIXEL-LEVEL SEGMENTATION FOR SEA ICE TYPES;Fully supervised deep learning approaches have demonstrated impressive accuracy in sea ice classification, but their dependence on high-resolution labels presents a significant challenge due to the difficulty of obtaining such data. In response, our weakly supervised learning method provides a compelling alternative by utilizing lower-resolution regional labels from expert-annotated ice charts. This approach achieves exceptional pixel-level classification performance by introducing regional loss representations during training to measure the disparity between predicted and ice chart-derived sea ice type distributions. Leveraging the AI4Arctic Sea Ice Challenge Dataset, our method outperforms the fully supervised U-Net benchmark, the top solution of the AutoIce challenge, in both mapping resolution and class-wise accuracy, marking a significant advancement in automated operational sea ice mapping.;"Muhammed Patel (University of Waterloo)*; Xinwei Chen (South China University of Technology); Linlin Xu (University of Waterloo); Yuhao Chen (University of Waterloo); K Andrea Scott (University of Waterloo); David A Clausi (University of Waterloo)";"Patel, Muhammed*; Chen, Xinwei; Xu, Linlin; Chen, Yuhao; Scott, K Andrea; Clausi, David A";Accept Poster60;Spatially Far, Ecologically Close: Evaluating Extrapolation on Vegetation Forecasting Models;"Geographically distributed data naturally varies from one location to another due to different environmental conditions between regions. This creates a representation or covariate shift in input variables between training and testing data when we apply a model to a different location. Theoretically, we expect this covariate shift to have a detrimental impact on model performance. However, this negative impact is hard to estimate beforehand merely from the input data, and trained models may perform surprisingly well even under distribution shifts.
This paper investigates how different covariate shift strategies impact the model performance on geospatial vegetation forecasting. 
In our experiments, we demonstrate that the model accurately predicts in locations far from the training samples in space by leveraging the similar ecological behavior of vegetation under comparable environmental conditions. 
We close with an extensive summary that outlines our findings and provides an outlook on discussion points that we hope to discuss in depth at the workshop.";"Claire Robin (Biogeochemical Integration, Max-Planck-Institute for Biogeochemistry, Jena, Germany)*; Melanie Weynants (Max Planck Institute for Biogeochemistry); Vitus Benson (Max-Planck-Institute for Biogeochemistry); Marc Rußwurm (Wageningen University); Nuno Carvalhais (Max-Planck-Institute for Biogeochemistry); Markus Reichstein (Max Planck Institute for Biogeochemistry, Jena; Michael Stifel Center Jena for Data-Driven and Simulation Science, Jena)";"Robin, Claire*; Weynants, Melanie; Benson, Vitus; Rußwurm, Marc; Carvalhais, Nuno; Reichstein, Markus";Accept Poster61;Seeing Through the Clouds: Cloud Gap Imputation with Prithvi Foundation Model;Filling cloudy pixels in multispectral satellite imagery is essential for accurate data analysis and downstream applications, especially for tasks which require time series data. To address this issue, we compare the performance of a foundational Vision Transformer (ViT) model with a baseline Conditional Generative Adversarial Network (CGAN) model for missing value imputation in time series of multispectral satellite imagery. We randomly mask time series of satellite images using real-world cloud masks and train each model to reconstruct the missing pixels. The ViT model is fine-tuned from a pretrained model, while the CGAN is trained from scratch. Using quantitative evaluation metrics such as structural similarity index and mean absolute error as well as qualitative visual analysis, we assess imputation accuracy and contextual preservation. ;"Denys Godwin (Clark University)*; Hanxi Li (Clark University); Michael Cecil (Clark University); Hamed Alemohammad (Clark University)";"Godwin, Denys*; Li, Hanxi; Cecil, Michael; Alemohammad, Hamed";Accept Poster62;Encoding Agent Trajectories as Representations with Sequence Transformers;Spatiotemporal data faces many analogous challenges to natural language text including the ordering of locations (words) in a sequence, long range dependencies between locations, and locations having multiple meanings. In this work, we propose a novel model for representing high dimensional spatiotemporal trajectories as sequences of discrete locations and encoding them with a Transformer-based neural network architecture. Similar to language models, our Sequence Transformer for Agent Representation Encodings (STARE) model learns these encoding through the supervisory signal of various tasks, e.g. classification of agent trajectories. We present experimental results on various synthetic and real trajectory datasets and show that our proposed STARE model can correctly learn labels along with meaningful encodings.;"Athanasios Tsiligkaridis (STR)*; Zhongheng Li (Systems and Technology Research); Elizabeth Hou (Systems and Technology Research)";"Tsiligkaridis, Athanasios*; Li, Zhongheng; Hou, Elizabeth";Accept Poster66;Synthetic data augmentation for earth observation object detection tasks;Neural networks have transformed remote sensing, making it easier to derive insights from satellite images for various Earth Observation (EO) applications. Yet, their potential is often limited by the lack of labeled data. Traditional data augmentation methods, while attempting to address this, require significant manual input and lack visual diversity, compromising model performance. We introduce an innovative data augmentation strategy that automates the generation and integration of objects into satellite imagery, enhancing datasets for object detection. Our method notably improves car detection model performance, surpassing traditional augmentation techniques.;"Syrine Khammari (Technical University of Munich)*; Enrique Fernández-Laguilhoat Sánchez-Biezma  (FlyPix AI GmbH); Sergey  Sukhanov  (FlyPix AI GmbH); Ivan Tankoyeu (FlyPix AI GmbH)";"Khammari, Syrine*; Fernández-Laguilhoat Sánchez-Biezma , Enrique; Sukhanov , Sergey ; Tankoyeu, Ivan";Accept Poster69;A BENCHMARK FOR GEOGRAPHIC DISTRIBUTION SHIFT IN SMALLHOLDER AGROFORESTRY: DO FOUNDATION MODELS IMPROVE OOD GENERALIZATION?;Recent improvements in deep learning for remote sensing have shown that it is possible to detect individual trees using high resolution satellite remote sensing data. However, there has not been an evaluation of the robustness of individual tree detection methods to distribution shifts across varying geographies, and this limits the applicability of these methods to diverse areas beyond the sites in which they were trained. To address this, we introduce a benchmark dataset comprising varying agro-ecological zones for remote sensing tree detection in agroforestry farms in India. We then use this dataset to conduct a geographic robustness evaluation of out-of-distribution performance of different deep learning approaches for remote sensing tree detection. Results indicate strong performance of deep learning in detecting trees under conventional evaluation, yet a significant drop in performance in out-of-distribution agro-ecological zones for baseline methods. We report some improvements with foundation model based approaches including SAM and Grounding DINO, but find that they also exhibit similar performance drops out-of-distribution. Our study pushes the boundaries of current research by challenging machine learning methods with a dataset and evaluation protocol that better represents real-world variability, shedding light on the robustness and adaptability of different individual tree detection methods. ;"Siddharth Sachdeva (Stanford University)*; Chandrasekhar Biradar (CIFOR-ICRAF); Isabel Lopez (Stanford University); David Lobell (Stanford University)";"Sachdeva, Siddharth*; Biradar, Chandrasekhar; Lopez, Isabel; Lobell, David";Accept Poster72;Physics Informed Modeling of Ecosystem Respiration  via Dynamic Mode Decomposition with Control Input ;Ecosystem respiration (Reco) represents a major component of the global carbon cycle, and accurate characterization of its dynamics is essential for a comprehensive understanding of ecosystem-climate interactions and the impacts of climate extremes. This paper presents a novel data-driven and physics-aware method for estimating Reco dynamics using the dynamic mode decomposition with control input (DMDc) technique. The proposed model represents Reco as a linear dynamical system with an autonomous component and an exogenous control input, such as air temperature (Tair), or other observed drivers, such as soil temperature and/or soil water content. This unique modeling approach allows controlled intervention to study the effects of different inputs on the system. Experimental results using Fluxnet2015  data show that the prediction accuracy of Reco dynamics achieved with DMDc is comparable to state-of-the-art methods, making it a promising tool for analyzing the dynamic behavior of different vegetation ecosystems in response to climate change. ;"Maha Shadaydeh (Computer Vision Group, Institute for Informatics, Friedrich-Schiller-University Jena)*; Joachim Denzler (Computer Vision Group, Friedrich Schiller University Jena, Germany); Mirco Migliavacca (European Commission Joint Research Centre)";"Shadaydeh, Maha*; Denzler, Joachim; Migliavacca, Mirco";Accept Poster